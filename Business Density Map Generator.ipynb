{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded API KEY AND SECRET FROM FILE\n"
     ]
    }
   ],
   "source": [
    "import gmplot\n",
    "import pandas as pd\n",
    "from yelpapi import YelpAPI\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "%run API_STUFF.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Scrape data from yelp from the zip codes provided and the search term.\n",
    "def search_yelp(state, term, zips):\n",
    "    #yelp API authorization and shared secret\n",
    "    yelp_api = YelpAPI(API_KEY, API_SECRET)\n",
    "    #run test search to get the center Lat and Long we need to center the map on and \n",
    "    #find total results for this zip\n",
    "    try:\n",
    "        search_results = yelp_api.search_query(term=term, location = state, limit = 1, radius_filter= 4000)\n",
    "    except:\n",
    "        search_results = yelp_api.search_query(term=term, location = state, limit = 1, radius_filter= 4000)\n",
    "    latitude = []\n",
    "    longitude = []\n",
    "    price = []\n",
    "    raiting = []\n",
    "    review_count = []\n",
    "    name = []\n",
    "    zipcode = []\n",
    "    ZIP = []\n",
    "    closed = 0\n",
    "    nozip = 0\n",
    "    #search each zip code in the array of zips from this state\n",
    "    for i, zipcode in enumerate(zips):\n",
    "        #print statement to follow progress of search\n",
    "        print('Processing zipcode {} of {}.  Zip : {}'.format(i,len(zips), zipcode), end = '\\r')\n",
    "        #sometimes yelp API throws errors, so try and if it fails try again.\n",
    "        try:\n",
    "            search_results = yelp_api.search_query(term=term, location = zipcode, limit = 1, radius_filter= 4000)\n",
    "        except:\n",
    "            search_results = yelp_api.search_query(term=term, location = zipcode, limit = 1, radius_filter= 4000)\n",
    "        #save total number of restuarants in search so we know how many pages to scrape\n",
    "        total_restaurants = search_results['total']\n",
    "        #Yelp only lets us scrap 1000 results so set the page counter accordingly, \n",
    "        #1000 OR total restaurants /50 results a page\n",
    "        if(total_restaurants<1000):\n",
    "            tosearch = total_restaurants//50\n",
    "        else:\n",
    "            tosearch = 20\n",
    "        #run the search on every yelp results query we are allowed to\n",
    "        for search in range(tosearch):\n",
    "\n",
    "            #get the results for the search 50 at a time\n",
    "            try:\n",
    "                newsearch = yelp_api.search_query(term=term, location = zipcode, limit = 50, offset = 50*search, radius_filter= 4000)\n",
    "            except:\n",
    "                newsearch = yelp_api.search_query(term=term, location = zipcode, limit = 50, offset = 50*search, radius_filter= 4000)\n",
    "            for entry in range(50):\n",
    "                #try to run the search, if yelp says no page, youve hit the end of the results so dont do anything\n",
    "                try:\n",
    "                    #if the business is open (or not closed) save the relavant information\n",
    "                    if(newsearch['businesses'][entry]['is_closed'] == False):\n",
    "                        latitude.append(newsearch['businesses'][entry]['coordinates']['latitude'])\n",
    "                        longitude.append(newsearch['businesses'][entry]['coordinates']['longitude'])\n",
    "                        name.append(newsearch['businesses'][entry]['id'])\n",
    "                        #some restaurants have no price rating and it was throwing an error, if no rating rate a 0\n",
    "                        try:\n",
    "                            price.append(newsearch['businesses'][entry]['price'])\n",
    "                        except:\n",
    "                            price.append('')\n",
    "                        raiting.append(newsearch['businesses'][entry]['rating'])\n",
    "                        review_count.append(newsearch['businesses'][entry]['review_count'])\n",
    "                        #some restaurants have no zip code saved, if this is the case save no zip, eliminate entry later\n",
    "                        try:\n",
    "                            ZIP.append(newsearch['businesses'][entry]['location']['zip_code'])\n",
    "                        except:\n",
    "                            ZIP.append('')\n",
    "                    #if entry is closed iterate closed counter just so we can know about them\n",
    "                    else:\n",
    "                        closed = closed + 1\n",
    "                except:\n",
    "                    None\n",
    "    #save all the data parsed from scraping into a dataframe\n",
    "    data = pd.DataFrame()\n",
    "    data['name'] = name\n",
    "    data['latitude'] = latitude\n",
    "    data['longitude'] = longitude\n",
    "    data['price'] = [len(x) for x in price]\n",
    "    data['raiting'] = raiting\n",
    "    data['review_count'] = review_count\n",
    "    data['Zipcode'] = ZIP\n",
    "    #print some basic info about the scrape we ran\n",
    "    print('{} businesses were closed and not included in the data'.format(closed))\n",
    "    print('{} businesses had no zip and were not included in the data'.format(nozip))\n",
    "    #return the dataframe as well as the central location that the map should be centered on\n",
    "    return data, search_results['region']['center']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_pop_data(location):\n",
    "    #https://blog.splitwise.com/2013/09/18/the-2010-us-census-population-by-zip-code-totally-free/\n",
    "    #load data referencing population to zip code\n",
    "    population_by_zip = pd.read_csv('Pop_by_zip.csv', names= ['Zipcode', 'Pop'], skiprows=1)\n",
    "    #make the zip code a numeric value\n",
    "    population_by_zip.Zipcode = pd.to_numeric(population_by_zip.Zipcode)\n",
    "    #http://federalgovernmentzipcodes.us/\n",
    "    #load the data referencing the latitude and longitude of each zip code\n",
    "    zip_code_lat_long = pd.read_csv('zipcode-database.csv')\n",
    "    #keep the columns that we want to use\n",
    "    zip_code_lat_long = zip_code_lat_long[['Zipcode', 'State', 'Lat', 'Long', 'City']]\n",
    "    #keep the entries from the state we are investigating\n",
    "    zip_code_lat_long = zip_code_lat_long[(zip_code_lat_long.State == location)]\n",
    "    #make the zip code a numeric value\n",
    "    zip_code_lat_long.Zipcode = pd.to_numeric(zip_code_lat_long.Zipcode)\n",
    "    #merge the data on zip code so we know the population by latitude and longitude\n",
    "    pop_by_lat_long = zip_code_lat_long.merge(population_by_zip, on='Zipcode', how='inner')\n",
    "    #fill Nan values with 1 for zip codes that have no people stored\n",
    "    pop_by_lat_long = pop_by_lat_long.fillna(1)\n",
    "    #placeholder for list of zips we are working with\n",
    "    zips = []\n",
    "    #generate an array of the zipcodes important to this state\n",
    "    for zipcode in pop_by_lat_long.Zipcode:\n",
    "        #exclude the zip code that Yelp isn't recognizing from MI\n",
    "        if len(str(zipcode)) == 5 and (zipcode != 48921):\n",
    "            zips.append(zipcode)\n",
    "    #return the dataframe and a list of the zip codes for this state\n",
    "    return pop_by_lat_long, zips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generates a list of lat and longs based on the density of businesses of the specified type per capita, the more \n",
    "#businesses the more times each lat long pair will be returned\n",
    "def reformat_pop_entries(df):\n",
    "    #create a new datafame with the appropriate headers\n",
    "    new_df = pd.DataFrame(columns = ['Lat', 'Long'])\n",
    "    #make sure the index count is sequential, used for tracking progress\n",
    "    df = df.reset_index(drop=True)\n",
    "    #placeholder array for heat value: a value that is higher when the density of businesses per capita is higher\n",
    "    heatvalue = []\n",
    "    #for each row (zipcode in the state that contains businesses of the search type), calculate businesses per capita \n",
    "    for ind, location in df.iterrows():\n",
    "        #print a progress report\n",
    "        print('On row {} of {}'.format(ind, len(df)), end = '\\r')\n",
    "        \n",
    "        #if people actually live in this zip code, calcultate the business density\n",
    "        if(location.Pop != 0):\n",
    "            heat = location['counts']/location.Pop\n",
    "        #else, assign this as nan, we can drop this later, nobody lives there\n",
    "        else:\n",
    "            heat = float('NaN')\n",
    "        #save the business density value in the list\n",
    "        heatvalue.append(heat)\n",
    "    #put together the new dataframe with our business density data\n",
    "    new_df['Lat'] = df.Lat\n",
    "    new_df['Long'] = df.Long\n",
    "    new_df['City'] = df.City\n",
    "    new_df['Pop'] = df.Pop\n",
    "    new_df['heatvalue'] = heatvalue\n",
    "    new_df = new_df.dropna()\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(new_df['heatvalue'])\n",
    "    #normalize the data from 1 to 0, the place with the highest density of target business type as 100, places with \n",
    "    #no businesses of the searched type as 0\n",
    "    new_df['heatvalue'] = scaler.transform(new_df['heatvalue'].reshape(-1, 1))*100\n",
    "    \n",
    "    #dropcount = []\n",
    "    #prepare the new dataframe that will contain lat long pairs\n",
    "    latlongcounts = pd.DataFrame()\n",
    "    #for each zip code\n",
    "    for i, location in new_df.iterrows():\n",
    "        #generate between 100 and 0 rows of lat long pairs depending on the density of the business type per capita\n",
    "        for number in range(int(round(location.heatvalue))):\n",
    "            #create a single entry for the heatmap to use as a measure of density\n",
    "            temp = pd.DataFrame([[location.Lat, location.Long, location.City]], columns=['Lat', 'Long', 'City'])\n",
    "            #add the entry to the dataframe\n",
    "            latlongcounts = latlongcounts.append(temp)\n",
    "    #make sure the index is sequential (it should already be but I like doing this)\n",
    "    latlongcounts = latlongcounts.reset_index(drop=True)\n",
    "    return latlongcounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        search_results = yelp_api.search_query(term=term, location def run(location, term):\n",
    "    #compile the list of populations by lat and long and retieve the  list of relavant zips\n",
    "    pop_by_zip, zips = load_pop_data(location)\n",
    "    #search yelp for all the entries we can find\n",
    "    restaurants, center = search_yelp(location, term, zips)\n",
    "    #initiate map data and center it on the middle of the state we are looking at\n",
    "    gmap = gmplot.GoogleMapPlotter(center['latitude'], center['longitude'], 7.5)\n",
    "    #because we are searching by zip with a range of 25 miles sometimes we will get duplicate entries \n",
    "    #drop entries will identical id values because we picked them up more than once by searching adjacent zips\n",
    "    restaurants.drop_duplicates(subset = 'name', inplace = True)\n",
    "    #set the count of each restuarant to 1 next to its entry, will be used by groupby function\n",
    "    restaurants['counts'] = 1\n",
    "    #group all the data by zip code so we know how many businesses are in each zip\n",
    "    restaurantcounts = restaurants.groupby('Zipcode', as_index=False).sum()\n",
    "    #drop the columns we aren't interested in\n",
    "    restaurantcounts = restaurantcounts[['Zipcode', 'counts']]\n",
    "    #prepare the zipcode to be merged by typing it as string\n",
    "    restaurantcounts['Zipcode'] = [str(x)  for x in restaurantcounts['Zipcode']]\n",
    "    #prepare the zipcode to be merged by typing it as string\n",
    "    pop_by_zip['Zipcode'] = [str(x)  for x in pop_by_zip['Zipcode']]\n",
    "    #merge the zipcode and population data with the restuarant counts by zip\n",
    "    pop_by_zip_w_b_counts = pop_by_zip.merge(restaurantcounts, on='Zipcode', how='outer')\n",
    "    #drop rows where there are nan values\n",
    "    pop_by_zip_w_b_counts_clean = pop_by_zip_w_b_counts.dropna()\n",
    "    #return a list of lats and longs that is generated by determining how many businesses of this type per capita\n",
    "    entries_adj_pop = reformat_pop_entries(pop_by_zip_w_b_counts_clean)\n",
    "    #plot out a heat map using lat and longs, the more businesses per capita the more times each lat long pair\n",
    "    #is in the entries_adj_pop dataframe\n",
    "    gmap.heatmap(entries_adj_pop.Lat, entries_adj_pop.Long, radius = 40)\n",
    "    #prepair the filename based of search terms\n",
    "    filename = term + '_in_' + location + \".html\"\n",
    "    #draw the file\n",
    "    gmap.draw(filename)\n",
    "    print('Map file saved as {}'.format(filename))\n",
    "    #return the dataframe that contains the counts of restaurants in each zip/city for inspection if needed\n",
    "    return pop_by_zip_w_b_counts_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 businesses were closed and not included in the data\n",
      "0 businesses had no zip and were not included in the data\n",
      "On row 503 of 748\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peter/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/home/peter/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:34: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On row 504 of 748\r",
      "On row 505 of 748\r",
      "On row 506 of 748\r",
      "On row 507 of 748\r",
      "On row 508 of 748\r",
      "On row 509 of 748\r",
      "On row 510 of 748\r",
      "On row 511 of 748\r",
      "On row 512 of 748\r",
      "On row 513 of 748\r",
      "On row 514 of 748\r",
      "On row 515 of 748\r",
      "On row 516 of 748\r",
      "On row 517 of 748\r",
      "On row 518 of 748\r",
      "On row 519 of 748\r",
      "On row 520 of 748\r",
      "On row 521 of 748\r",
      "On row 522 of 748\r",
      "On row 523 of 748\r",
      "On row 524 of 748\r",
      "On row 525 of 748\r",
      "On row 526 of 748\r",
      "On row 527 of 748\r",
      "On row 528 of 748\r",
      "On row 529 of 748\r",
      "On row 530 of 748\r",
      "On row 531 of 748\r",
      "On row 532 of 748\r",
      "On row 533 of 748\r",
      "On row 534 of 748\r",
      "On row 535 of 748\r",
      "On row 536 of 748\r",
      "On row 537 of 748\r",
      "On row 538 of 748\r",
      "On row 539 of 748\r",
      "On row 540 of 748\r",
      "On row 541 of 748\r",
      "On row 542 of 748\r",
      "On row 543 of 748\r",
      "On row 544 of 748\r",
      "On row 545 of 748\r",
      "On row 546 of 748\r",
      "On row 547 of 748\r",
      "On row 548 of 748\r",
      "On row 549 of 748\r",
      "On row 550 of 748\r",
      "On row 551 of 748\r",
      "On row 552 of 748\r",
      "On row 553 of 748\r",
      "On row 554 of 748\r",
      "On row 555 of 748\r",
      "On row 556 of 748\r",
      "On row 557 of 748\r",
      "On row 558 of 748\r",
      "On row 559 of 748\r",
      "On row 560 of 748\r",
      "On row 561 of 748\r",
      "On row 562 of 748\r",
      "On row 563 of 748\r",
      "On row 564 of 748\r",
      "On row 565 of 748\r",
      "On row 566 of 748\r",
      "On row 567 of 748\r",
      "On row 568 of 748\r",
      "On row 569 of 748\r",
      "On row 570 of 748\r",
      "On row 571 of 748\r",
      "On row 572 of 748\r",
      "On row 573 of 748\r",
      "On row 574 of 748\r",
      "On row 575 of 748\r",
      "On row 576 of 748\r",
      "On row 577 of 748\r",
      "On row 578 of 748\r",
      "On row 579 of 748\r",
      "On row 580 of 748\r",
      "On row 581 of 748\r",
      "On row 582 of 748\r",
      "On row 583 of 748\r",
      "On row 584 of 748\r",
      "On row 585 of 748\r",
      "On row 586 of 748\r",
      "On row 587 of 748\r",
      "On row 588 of 748\r",
      "On row 589 of 748\r",
      "On row 590 of 748\r",
      "On row 591 of 748\r",
      "On row 592 of 748\r",
      "On row 593 of 748\r",
      "On row 594 of 748\r",
      "On row 595 of 748\r",
      "On row 596 of 748\r",
      "On row 597 of 748\r",
      "On row 598 of 748\r",
      "On row 599 of 748\r",
      "On row 600 of 748\r",
      "On row 601 of 748\r",
      "On row 602 of 748\r",
      "On row 603 of 748\r",
      "On row 604 of 748\r",
      "On row 605 of 748\r",
      "On row 606 of 748\r",
      "On row 607 of 748\r",
      "On row 608 of 748\r",
      "On row 609 of 748\r",
      "On row 610 of 748\r",
      "On row 611 of 748\r",
      "On row 612 of 748\r",
      "On row 613 of 748\r",
      "On row 614 of 748\r",
      "On row 615 of 748\r",
      "On row 616 of 748\r",
      "On row 617 of 748\r",
      "On row 618 of 748\r",
      "On row 619 of 748\r",
      "On row 620 of 748\r",
      "On row 621 of 748\r",
      "On row 622 of 748\r",
      "On row 623 of 748\r",
      "On row 624 of 748\r",
      "On row 625 of 748\r",
      "On row 626 of 748\r",
      "On row 627 of 748\r",
      "On row 628 of 748\r",
      "On row 629 of 748\r",
      "On row 630 of 748\r",
      "On row 631 of 748\r",
      "On row 632 of 748\r",
      "On row 633 of 748\r",
      "On row 634 of 748\r",
      "On row 635 of 748\r",
      "On row 636 of 748\r",
      "On row 637 of 748\r",
      "On row 638 of 748\r",
      "On row 639 of 748\r",
      "On row 640 of 748\r",
      "On row 641 of 748\r",
      "On row 642 of 748\r",
      "On row 643 of 748\r",
      "On row 644 of 748\r",
      "On row 645 of 748\r",
      "On row 646 of 748\r",
      "On row 647 of 748\r",
      "On row 648 of 748\r",
      "On row 649 of 748\r",
      "On row 650 of 748\r",
      "On row 651 of 748\r",
      "On row 652 of 748\r",
      "On row 653 of 748\r",
      "On row 654 of 748\r",
      "On row 655 of 748\r",
      "On row 656 of 748\r",
      "On row 657 of 748\r",
      "On row 658 of 748\r",
      "On row 659 of 748\r",
      "On row 660 of 748\r",
      "On row 661 of 748\r",
      "On row 662 of 748\r",
      "On row 663 of 748\r",
      "On row 664 of 748\r",
      "On row 665 of 748\r",
      "On row 666 of 748\r",
      "On row 667 of 748\r",
      "On row 668 of 748\r",
      "On row 669 of 748\r",
      "On row 670 of 748\r",
      "On row 671 of 748\r",
      "On row 672 of 748\r",
      "On row 673 of 748\r",
      "On row 674 of 748\r",
      "On row 675 of 748\r",
      "On row 676 of 748\r",
      "On row 677 of 748\r",
      "On row 678 of 748\r",
      "On row 679 of 748\r",
      "On row 680 of 748\r",
      "On row 681 of 748\r",
      "On row 682 of 748\r",
      "On row 683 of 748\r",
      "On row 684 of 748\r",
      "On row 685 of 748\r",
      "On row 686 of 748\r",
      "On row 687 of 748\r",
      "On row 688 of 748\r",
      "On row 689 of 748\r",
      "On row 690 of 748\r",
      "On row 691 of 748\r",
      "On row 692 of 748\r",
      "On row 693 of 748\r",
      "On row 694 of 748\r",
      "On row 695 of 748\r",
      "On row 696 of 748\r",
      "On row 697 of 748\r",
      "On row 698 of 748\r",
      "On row 699 of 748\r",
      "On row 700 of 748\r",
      "On row 701 of 748\r",
      "On row 702 of 748\r",
      "On row 703 of 748\r",
      "On row 704 of 748\r",
      "On row 705 of 748\r",
      "On row 706 of 748\r",
      "On row 707 of 748\r",
      "On row 708 of 748\r",
      "On row 709 of 748\r",
      "On row 710 of 748\r",
      "On row 711 of 748\r",
      "On row 712 of 748\r",
      "On row 713 of 748\r",
      "On row 714 of 748\r",
      "On row 715 of 748\r",
      "On row 716 of 748\r",
      "On row 717 of 748\r",
      "On row 718 of 748\r",
      "On row 719 of 748\r",
      "On row 720 of 748\r",
      "On row 721 of 748\r",
      "On row 722 of 748\r",
      "On row 723 of 748\r",
      "On row 724 of 748\r",
      "On row 725 of 748\r",
      "On row 726 of 748\r",
      "On row 727 of 748\r",
      "On row 728 of 748\r",
      "On row 729 of 748\r",
      "On row 730 of 748\r",
      "On row 731 of 748\r",
      "On row 732 of 748\r",
      "On row 733 of 748\r",
      "On row 734 of 748\r",
      "On row 735 of 748\r",
      "On row 736 of 748\r",
      "On row 737 of 748\r",
      "On row 738 of 748\r",
      "On row 739 of 748\r",
      "On row 740 of 748\r",
      "On row 741 of 748\r",
      "On row 742 of 748\r",
      "On row 743 of 748\r",
      "On row 744 of 748\r",
      "On row 745 of 748\r",
      "On row 746 of 748\r",
      "On row 747 of 748\r",
      "Map file saved as Pizza_in_MI.html\n"
     ]
    }
   ],
   "source": [
    "allstuff = run(location = 'MI',term =  'Pizza')        search_results = yelp_api.search_query(term=term, location "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "allstuff = run(location = 'CA',term =  'Pizza')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "allstuff = run(location = 'PA',term =  'Chinese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allstuff = run(location = 'PA',term =  'PIZZA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
